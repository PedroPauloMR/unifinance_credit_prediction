{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import pandera\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandera import Check, Column, DataFrameSchema\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['target', 'TaxaDeUtilizacaoDeLinhasNaoGarantidas',\n",
    "       'Idade', 'NumeroDeVezes30-59DiasAtrasoNaoPior', 'TaxaDeEndividamento',\n",
    "       'RendaMensal', 'NumeroDeLinhasDeCreditoEEmprestimosAbertos',\n",
    "       'NumeroDeVezes90DiasAtraso', 'NumeroDeEmprestimosOuLinhasImobiliarias',\n",
    "       'NumeroDeVezes60-89DiasAtrasoNaoPior', 'NumeroDeDependentes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoad:\n",
    "    \"\"\"Class data load\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"This function will load the dataset\n",
    "        return:\n",
    "        pandas DataFrame\"\"\"\n",
    "        loaded_data = pd.read_csv('../data/raw/train.csv')\n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dl.load_data()[columns_to_use]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, columns_to_use) -> None:\n",
    "        self.columns_to_use = columns_to_use\n",
    "\n",
    "    def check_shape_data(self, dataframe: pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            print('Initiating validation...')\n",
    "            dataframe.columns = self.columns_to_use\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f'Error on validation: {e}')\n",
    "            return False\n",
    "        \n",
    "    def chek_columns(self, dataframe: pd.DataFrame) -> bool:\n",
    "        schema = DataFrameSchema(\n",
    "            {\n",
    "                \"target\": Column(int, Check.isin([0, 1]), Check(lambda x: x > 0), coerce=True),\n",
    "                \"TaxaDeUtilizacaoDeLinhasNaoGarantidas\": Column(float, nullable=True),\n",
    "                \"Idade\": Column(int, nullable=True),\n",
    "                \"NumeroDeVezes30-59DiasAtrasoNaoPior\": Column(int, nullable=True),\n",
    "                \"TaxaDeEndividamento\": Column(float, nullable=True),\n",
    "                \"RendaMensal\": Column(float, nullable=True),\n",
    "                \"NumeroDeLinhasDeCreditoEEmprestimosAbertos\": Column(int, nullable=True),\n",
    "                \"NumeroDeVezes90DiasAtraso\": Column(int, nullable=True),\n",
    "                \"NumeroDeEmprestimosOuLinhasImobiliarias\": Column(int, nullable=True),\n",
    "                \"NumeroDeVezes60-89DiasAtrasoNaoPior\": Column(int, nullable=True),\n",
    "                \"NumeroDeDependentes\": Column(float, nullable=True)\n",
    "            }\n",
    "        )\n",
    "        try:\n",
    "            schema.validate(dataframe)\n",
    "            print('Validation columns passed...')\n",
    "            return True\n",
    "        except pandera.errors.SchemaErrors as exc:\n",
    "            print('Validation columns failed...')\n",
    "            pandera.display(exc.failure_cases)\n",
    "            return False\n",
    "        \n",
    "    def run(self, dataframe : pd.DataFrame) -> bool:\n",
    "        if self.check_shape_data(dataframe) and self.chek_columns(dataframe):\n",
    "            print('Success on validate data')\n",
    "            return True\n",
    "        else:\n",
    "            print('Failed on validation')\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DataValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.run(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, dataframe : pd.DataFrame, target_name : str):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_name = target_name\n",
    "\n",
    "    def train_test_spliting(self):\n",
    "        X = self.dataframe.drop( self.target_name, axis = 1)\n",
    "        y = self.dataframe[self.target_name]\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "        return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTransformation(df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = dt.train_test_spliting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape: ',X_train.shape)\n",
    "print('Test shape: ',X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self, dataframe: pd.DataFrame,pipe: Pipeline):\n",
    "        self.dataframe = dataframe\n",
    "        self.pipe = pipe \n",
    "        \n",
    "    def pipeline(self):\n",
    "        train_pipe = self.pipe\n",
    "        train_pipe.fit(self.dataframe)\n",
    "        return train_pipe \n",
    "    \n",
    "    def run(self):\n",
    "        print('Initiating preprocessing...')\n",
    "        trained_pipeline = self.pipeline()\n",
    "        data_preprocessed = trained_pipeline.transform(self.dataframe)\n",
    "        return data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "    ('imputer', MeanMedianImputer(variables=['RendaMensal','NumeroDeDependentes'])),\n",
    "        ('discretizer', EqualFrequencyDiscretiser(variables=['TaxaDeUtilizacaoDeLinhasNaoGarantidas', 'TaxaDeEndividamento', 'RendaMensal'])),\n",
    "            ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "        ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dp = DataPreprocess(X_train, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = dp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(dp.pipeline(),'preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModels:\n",
    "    def __init__(self, dados_X: pd.DataFrame,dados_y: pd.DataFrame):\n",
    "        self.dados_X = dados_X \n",
    "        self.dados_y = dados_y \n",
    "        \n",
    "    def train(self, model):\n",
    "        model.fit(self.dados_X, self.dados_y)\n",
    "        joblib.dump(model, 'modelo.pkl')\n",
    "        return model \n",
    "    \n",
    "    def predict(self, dados_para_prever: pd.DataFrame):\n",
    "        model_fitted = self._load_model()\n",
    "        dados_pred = model_fitted.predict_proba(dados_para_prever)\n",
    "        return dados_pred\n",
    "    \n",
    "    def _load_model(self):\n",
    "        model = joblib.load('modelo.pkl')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TrainModels(dados_X=X_train_processed,dados_y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.train(model=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tm.predict(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = dp.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_processed = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = tm.predict(X_val_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def eval_metrics(self, dados_reais, dados_preditos):\n",
    "        roc_auc = roc_auc_score(dados_reais, dados_preditos)\n",
    "        return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = ModelEvaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.eval_metrics(y_train, y_train_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.eval_metrics(y_val, y_val_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. etapa\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('imputer', MeanMedianImputer(variables=['RendaMensal','NumeroDeDependentes'])),\n",
    "            ('discretizer', EqualFrequencyDiscretiser(variables=['TaxaDeUtilizacaoDeLinhasNaoGarantidas', 'TaxaDeEndividamento','RendaMensal'])),\n",
    "            ('scaler', SklearnTransformerWrapper(RobustScaler()))\n",
    "                 ]\n",
    "                 )\n",
    "dp = DataPreprocess(X_train, pipe)\n",
    "X_train_processed = dp.run()\n",
    "\n",
    "#---------------------#\n",
    "#2. etapa\n",
    "tm = TrainModels(dados_X=X_train_processed,dados_y = y_train)\n",
    "tm.train(model=LogisticRegression(penalty='l2', max_iter=1500, solver='newton-cholesky'))\n",
    "y_val_pred = tm.predict(X_val_processed)\n",
    "\n",
    "#---------------------#\n",
    "# 3.etapa\n",
    "me = ModelEvaluation()\n",
    "me.eval_metrics(y_val, y_val_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
